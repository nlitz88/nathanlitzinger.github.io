<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Building a Bird Feeder Live Stream | Nathan Litzinger</title><meta name=keywords content><meta name=description content="As my Spring 2021 semester was nearing completion, I found myself looking for ways to &ldquo;productively procrastinate&rdquo; studying for finals. Like many others at the time, COVID had led my family to resurrect our bird feeders as another at-home distraction. While it was fun seeing all kinds of new birds emerge from our woods, I soon found myself in a predicament: I couldn&rsquo;t see the birds for the majority of the day."><meta name=author content="Nathan Litzinger"><link rel=canonical href=https://nlitz88.github.io/posts/birdstream/birdstream/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://nlitz88.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://nlitz88.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://nlitz88.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://nlitz88.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://nlitz88.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="Building a Bird Feeder Live Stream"><meta property="og:description" content="As my Spring 2021 semester was nearing completion, I found myself looking for ways to &ldquo;productively procrastinate&rdquo; studying for finals. Like many others at the time, COVID had led my family to resurrect our bird feeders as another at-home distraction. While it was fun seeing all kinds of new birds emerge from our woods, I soon found myself in a predicament: I couldn&rsquo;t see the birds for the majority of the day."><meta property="og:type" content="article"><meta property="og:url" content="https://nlitz88.github.io/posts/birdstream/birdstream/"><meta property="og:image" content="https://nlitz88.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-01-06T06:11:36+00:00"><meta property="article:modified_time" content="2022-01-06T06:11:36+00:00"><meta property="og:site_name" content="Nathan Litzinger"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://nlitz88.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Building a Bird Feeder Live Stream"><meta name=twitter:description content="As my Spring 2021 semester was nearing completion, I found myself looking for ways to &ldquo;productively procrastinate&rdquo; studying for finals. Like many others at the time, COVID had led my family to resurrect our bird feeders as another at-home distraction. While it was fun seeing all kinds of new birds emerge from our woods, I soon found myself in a predicament: I couldn&rsquo;t see the birds for the majority of the day."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://nlitz88.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Building a Bird Feeder Live Stream","item":"https://nlitz88.github.io/posts/birdstream/birdstream/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Building a Bird Feeder Live Stream","name":"Building a Bird Feeder Live Stream","description":"As my Spring 2021 semester was nearing completion, I found myself looking for ways to \u0026ldquo;productively procrastinate\u0026rdquo; studying for finals. Like many others at the time, COVID had led my family to resurrect our bird feeders as another at-home distraction. While it was fun seeing all kinds of new birds emerge from our woods, I soon found myself in a predicament: I couldn\u0026rsquo;t see the birds for the majority of the day.","keywords":[],"articleBody":" As my Spring 2021 semester was nearing completion, I found myself looking for ways to “productively procrastinate” studying for finals. Like many others at the time, COVID had led my family to resurrect our bird feeders as another at-home distraction. While it was fun seeing all kinds of new birds emerge from our woods, I soon found myself in a predicament: I couldn’t see the birds for the majority of the day.\nAs most computer engineering students can attest to, I spent all day in my room challenging my understanding of pipeline architecture and virtual memory translation optimizations–especially before finals week. Fun, right? Well, maybe for the first five hours. When I wanted a break from losing my hair–that’s when I could venture outside or sit in our kitchen and watch the birds.\nThen I finally thought–why don’t I just stream it? Revolutionary, I know.\nThe Initial Setup Initially, I just needed a simple way of pointing a camera at the bird feeder and magically having the video stream appear in my room. To do this, I started with what I knew: OBS.\nThe plan was to just set up an old Windows laptop in our living room, plug in a webcam, and spin up a broadcast with OBS. Naturally, I started with exactly that. I immediately ran into problems:\nThe over 10 year old laptop I was trying to use just couldn’t hack the H.264 encoding needed to compress the video stream. I simply didn’t have the wireless bandwidth at this spot in our house (at the time) to pull off a stable stream even if the laptop could have kept up. The webcam (naturally) had zero optics, and I was left with an image of the feeders from about 15 feet away. Perfect, right? Everything was off to a great start :,)\nIt’s also worth mentioning that the bandwidth issue would just have to be addressed one way or another, and an ethernet homerun was not in the picture for this setup.\nThe New Plan With these problems in mind, I had to start thinking of some alternatives to an old, debilitated laptop and webcam. What would be capable of compressing a video stream quickly enough, and what kind of camera did I need to really capture what I wanted?\nThe Camera For starters, I needed a camera that\nWouldn’t break the bank Actually had optical zoom Could run for hours on end without issue The camera I eventually landed on was a slightly disfunctional Canon Vixia HF R82. The R82 was a perfect option: a camera meant for recording video (camcorder), had 32x optical zoom, and was cheap–well, mine was. I found an R82 on eBay listed for parts. Simply put, it can’t run on battery, but works just fine plugged in. For this project, that was a non-issue.\nThe Computer To reiterate, I needed something that could encode video in H.264 without a sweat. Ideally, it would have a GPU to do this for me. Also, because this was going in my family’s living room, I didn’t want it to be loud or throw off a ton of heat. While there were plenty of desktop options out there, I decided to give an NVidia Jetson Nano 4GB a shot. The Software This is where things got fun! I had my high level plan in mind, but now I actually had to figure out how I was going to pull this off. Initially I thought I might just install OBS on the Jetson, but as I quickly learned, this was not a viable option. Back to the drawing boards, my new plan was now to:\ncompress the camera feed stream it over the network run obs on another server to manage/ingest the remote stream control OBS to start/stop the stream at sunrise/sunset I had recently been watching a Paul McWhorter video where he streamed a Raspicam’s video stream over the network using gstreamer. Up until now, I had only ever heard of ffmpeg for transcoding video files, so gstreamer seemed like uncharted waters. This was where the fun began, however.\nAlso, I wanted some way of using OBS to actually send the final stream off to YouTube and/or Twitch. This would involve setting up a virtual machine or another computer with the hardware capabilities of decoding and encoding the stream before sending it off.\ngstreamer I began looking for examples of gstreamer pipelines to take the live camera feed, encode it, and send it off to my RTMP server. While seemingly simple at the surface, I had a fair bit of learning ahead of me just to understand how to piece together the different elements of the pipeline to achieve what I needed.\nAfter toying through all kinds of examples online and scouring every Nvidia forum post there is, I landed on the following pipeline:\ngst-launch-1.0 v4l2src device=/dev/video0 ! image/jpeg,width=1920,height=1080,framerate=60/1 ! jpegdec ! video/x-raw ! nvvidconv ! 'video/x-raw(memory:NVMM),format=I420' ! nvv4l2h264enc bitrate=30000000 maxperf-enable=1 ! h264parse ! flvmux ! rtmpsink location=\"rtmp://192.168.0.90/live/test live=1\"\nGranted, this isn’t the perfect pipeline. I didn’t get exactly what I wanted out of it. My goal was to get the Jetson to be able to capture and encode a 1080p 60 FPS stream to my local RTMP server. However, the best I could get was 1080p 30 FPS.\nThe core of the issue is likely due to the amount of work the CPU has to due with the above pipeline. The problem (or, limitation I suppose) is in the nvjpegdec element/plugin for gstreamer. See, in a perfect world, I could pipe the MJPEG video stream from the camera into nvjpegdec and have nvjpegdec output directly to the nvv4l2h264 encoder. This should work in theory, as nvjpegdec is able to operate on data in the GPU’s memory. Then, nvv4l2h264 can encode the data directly from the GPU memory, without any need to move the data back to the main system memory. What this all means is that the gpu should’ve been able to do most of the work.\nSadly, however, the nvjpegdec gstreamer element doesn’t quite work like it’s supposed to. According to an Nvidia dev, a patch is required to the element to get it to function as desired. I did try to go through and patch it myself according to the (vague) instructions, but I either missed something along the way or the patch is outdated.\nI’d like to think that if I could’ve gotten this patch to work, the entire workload could be offloaded to the GPU and I could’ve easily achieved 1080p 60 FPS. So, in its current state, the best I could do was to use the non-nvidia jpegdec element and offload the jpeg decoding to the CPU. Maybe when I come back to this project I’ll have some more time to look into this further or get some more help.\nIn the meantime, however, I accepted the performance hit and created a systemd service to launch the pipeline and get things started automatically.\nNetwork Stream Once the Jetson did its part to decode the MJPEG and encode it in H.264, all it had to do was send it over the network to an RTMP server. This way, I could access the video stream as an RTMP video input on another server running OBS. Additionally, I could also use that RTMP server to rebroadcast the stream from OBS to multiple streaming platforms.\nInitially, I didn’t have a server with a GPU to run OBS and efficiently encode its own stream, so I used my desktop. While this worked fine, I didn’t want to have to leave on an R9-390X heater in my room, and I didn’t have much faith in that being a stable set up anyways.\nSo, rather than pulling in the stream from the Jetson on some OBS instance, I instead decided that I would just send the stream from the Jetson to the RTMP server, and then directly from the RTMP endpoint to all of the broadcasting platforms I wanted.\nThe Result (For Now) So far, the basic stream set up works almost all on its own, but often needs some attention. Whether its setting the camera back up after a brown-out or restarting the stream due to me bringing the network down.\nDepending on whether or not I’m working on it or messing with something, you will usually find the stream up at the feeder’s dedicated YouTube Channel Chirp. Until I add some better automation, when the stream is up, it runs 24/7, so you can check it out anytime (though you won’t see too much at night!).\nWhat’s Still To Come Busy with school and internship work, I haven’t quite had the time yet to build out the automation scripts to control OBS. Plus, I have temporarily replaced the Jetson with another old Windows desktop until I have more time to work with it.\nStream Control Scripts Just to clarify, these should just be some basic Python scripts or maybe an API of some sort that I can use to control the stream. That is, they will automate starting/stopping the stream based on the time of day, switching scenes to a different camera, etc.\nMultiple Cameras Speaking of more cameras: Yes! I bought yet another Vixia. This time around, I found a great deal on an HF R400. I did some more research on these cameras and eventually realized that there haven’t been any significant changes the underlying camera platform since the 400 up to the 800 (like my R82). That in mind, I found a good deal on one and jumped on it.\nNow, I didn’t just buy another camera to have a picture in picture or something like that–no. I wanted to solve the problem of not being able to get up close and personal with the birds on a particular feeder. The stream is SO much cooler to watch when the entire shot is a close up of some bird. Otherwise, we’re stuck with the pretty bog-standard webcam-like view of the birds that just isn’t as captivating.\nObject Detection? Machine Learning? Birds? Buzzwords aside, what’s the plan for these cameras then? Well, the idea is to direct each camera at only a single feeder or group of feeders. THEN, using some sort of object detection machine learning model (maybe some smaller YOLO model or similar), I can switch to whichever camera sees the most birds, for instance–something along those lines. This way, the feeder stream offers a totally hands-off, automated, and intelligent view of our local birds.\nPlus, if I go deeper down the machine learning rabbit-hole (or if someone else does and I just use their model), I may even be able to classify different birds as they appear! For now, these are future plans that don’t have time allotted to them yet, but in time I hope to bring them to life.\nWhere Will These Machine Learning Models Run? I have no idea. I still a lot of playing around with stuff like this to figure out what exactly I’ll need to pull it off. It’d be great if the Jetson could run models like this–In fact, I don’t think it’s unheard of to run Yolo (at some framerate) on the Jetson Nano. However, more sophisticated or less efficient models may to prove to be a bit less forgiving.\nIn any case, running the models “at the edge” would be great! I would imagine the Jetson’s SOC would run things like this much more efficiently in terms of power, despite maybe not being as performant. If not, however, running one of these models on one of my servers with an a GTX 1050 also wouldn’t be out of the question.\n","wordCount":"1949","inLanguage":"en","datePublished":"2022-01-06T06:11:36Z","dateModified":"2022-01-06T06:11:36Z","author":{"@type":"Person","name":"Nathan Litzinger"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://nlitz88.github.io/posts/birdstream/birdstream/"},"publisher":{"@type":"Organization","name":"Nathan Litzinger","logo":{"@type":"ImageObject","url":"https://nlitz88.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://nlitz88.github.io/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://nlitz88.github.io/litzingernathanresume.pdf title=Resume><span>Resume</span></a></li><li><a href=https://nlitz88.github.io/posts title=Posts><span>Posts</span></a></li><li><a href=https://nlitz88.github.io/photography title=Photography><span>Photography</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://nlitz88.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://nlitz88.github.io/posts/>Posts</a></div><h1 class=post-title>Building a Bird Feeder Live Stream</h1><div class=post-meta>January 6, 2022&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Nathan Litzinger&nbsp;|&nbsp;<a href=https://github.com/nlitz88/portfolio/content/posts/birdstream/birdstream.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p><a href="https://www.twitch.tv/nlitz88/clip/GracefulRefinedHareAMPEnergy-IbvAFHJng2ec0g4y?filter=clips&amp;range=all&amp;sort=time"><img loading=lazy src=/posts/birdstream/birdcampreview.png alt=Birdcam></a></p><p>As my Spring 2021 semester was nearing completion, I found myself looking for ways to &ldquo;productively procrastinate&rdquo; studying for finals. Like many others at the time, COVID had led my family to resurrect our bird feeders as another at-home distraction. While it was fun seeing all kinds of new birds emerge from our woods, I soon found myself in a predicament: I couldn&rsquo;t see the birds for the majority of the day.</p><p>As most computer engineering students can attest to, I spent all day in my room challenging my understanding of pipeline architecture and virtual memory translation optimizations&ndash;especially before finals week. Fun, right? Well, maybe for the first five hours. When I wanted a break from losing my hair&ndash;that&rsquo;s when I could venture outside or sit in our kitchen and watch the birds.</p><p>Then I finally thought&ndash;why don&rsquo;t I just stream it? Revolutionary, I know.</p><h2 id=the-initial-setup>The Initial Setup<a hidden class=anchor aria-hidden=true href=#the-initial-setup>#</a></h2><p>Initially, I just needed a simple way of pointing a camera at the bird feeder and magically having the video stream appear in my room. To do this, I started with what I knew: <strong>OBS</strong>.</p><p>The plan was to just set up an old Windows laptop in our living room, plug in a webcam, and spin up a broadcast with OBS. Naturally, I started with exactly that. I immediately ran into problems:</p><ol><li>The over 10 year old laptop I was trying to use just couldn&rsquo;t hack the H.264 encoding needed to compress the video stream.</li><li>I simply didn&rsquo;t have the wireless bandwidth at this spot in our house (at the time) to pull off a stable stream even if the laptop could have kept up.</li><li>The webcam (naturally) had zero optics, and I was left with an image of the feeders from about 15 feet away. Perfect, right?</li></ol><p>Everything was off to a <em>great</em> start :,)</p><p><em>It&rsquo;s also worth mentioning that the bandwidth issue would just have to be addressed one way or another, and an ethernet homerun was not in the picture for this setup.</em></p><h2 id=the-new-plan>The New Plan<a hidden class=anchor aria-hidden=true href=#the-new-plan>#</a></h2><p>With these problems in mind, I had to start thinking of some alternatives to an old, debilitated laptop and webcam. What would be capable of compressing a video stream quickly enough, and what kind of camera did I need to really capture what I wanted?</p><h3 id=the-camera>The Camera<a hidden class=anchor aria-hidden=true href=#the-camera>#</a></h3><p>For starters, I needed a camera that</p><ol><li>Wouldn&rsquo;t break the bank</li><li>Actually had optical zoom</li><li>Could run for hours on end without issue</li></ol><p>The camera I eventually landed on was a slightly disfunctional <strong>Canon Vixia HF R82</strong>.
<img loading=lazy src=/posts/birdstream/r82.gif alt=Camera>
The R82 was a perfect option: a camera meant for recording video (camcorder), had 32x optical zoom, and was cheap&ndash;well, mine was. I found an R82 on eBay listed for parts. Simply put, it can&rsquo;t run on battery, but works just fine plugged in. For this project, that was a non-issue.</p><h3 id=the-computer>The Computer<a hidden class=anchor aria-hidden=true href=#the-computer>#</a></h3><p>To reiterate, I needed something that could encode video in H.264 without a sweat. Ideally, it would have a GPU to do this for me. Also, because this was going in my family&rsquo;s living room, I didn&rsquo;t want it to be loud or throw off a ton of heat. While there were plenty of desktop options out there, I decided to give an NVidia Jetson Nano 4GB a shot.
<img loading=lazy src=/posts/birdstream/jetson.jpg alt=Jetson></p><h2 id=the-software>The Software<a hidden class=anchor aria-hidden=true href=#the-software>#</a></h2><p>This is where things got fun! I had my high level plan in mind, but now I actually had to figure out how I was going to pull this off. Initially I thought I might just install OBS on the Jetson, but as I quickly learned, this was not a viable option. Back to the drawing boards, my new plan was now to:</p><ol><li>compress the camera feed</li><li>stream it over the network</li><li>run obs on another server to manage/ingest the remote stream</li><li>control OBS to start/stop the stream at sunrise/sunset</li></ol><p>I had recently been watching a Paul McWhorter video where he streamed a Raspicam&rsquo;s video stream over the network using <strong>gstreamer</strong>. Up until now, I had only ever heard of ffmpeg for transcoding video files, so gstreamer seemed like uncharted waters. This was where the fun began, however.</p><p>Also, I wanted some way of using OBS to actually send the final stream off to YouTube and/or Twitch. This would involve setting up a virtual machine or another computer with the hardware capabilities of decoding and encoding the stream before sending it off.</p><h3 id=gstreamer>gstreamer<a hidden class=anchor aria-hidden=true href=#gstreamer>#</a></h3><p>I began looking for examples of gstreamer pipelines to take the live camera feed, encode it, and send it off to my RTMP server. While seemingly simple at the surface, I had a fair bit of learning ahead of me just to understand how to piece together the different elements of the pipeline to achieve what I needed.</p><p>After toying through all kinds of examples online and scouring every Nvidia forum post there is, I landed on the following pipeline:</p><p><code>gst-launch-1.0 v4l2src device=/dev/video0 ! image/jpeg,width=1920,height=1080,framerate=60/1 ! jpegdec ! video/x-raw ! nvvidconv ! 'video/x-raw(memory:NVMM),format=I420' ! nvv4l2h264enc bitrate=30000000 maxperf-enable=1 ! h264parse ! flvmux ! rtmpsink location="rtmp://192.168.0.90/live/test live=1"</code></p><p>Granted, this isn&rsquo;t the <em>perfect</em> pipeline. I didn&rsquo;t get exactly what I wanted out of it. My goal was to get the Jetson to be able to capture and encode a 1080p 60 FPS stream to my local RTMP server. However, the best I could get was 1080p 30 FPS.</p><p>The core of the issue is likely due to the amount of work the CPU has to due with the above pipeline. The problem (or, limitation I suppose) is in the <strong>nvjpegdec</strong> element/plugin for gstreamer. See, in a perfect world, I could pipe the MJPEG video stream from the camera into <strong>nvjpegdec</strong> and have nvjpegdec output directly to the nvv4l2h264 encoder. This should work in theory, as nvjpegdec is able to operate on data in the GPU&rsquo;s memory. Then, nvv4l2h264 can encode the data directly from the GPU memory, without any need to move the data back to the main system memory. What this all means is that the <strong>gpu should&rsquo;ve been able to do most of the work</strong>.</p><p>Sadly, however, the <strong>nvjpegdec</strong> gstreamer element doesn&rsquo;t quite work like it&rsquo;s supposed to. According to an Nvidia dev, a patch is required to the element to get it to function as desired. I did try to go through and patch it myself according to the (vague) instructions, but I either missed something along the way or the patch is outdated.</p><p>I&rsquo;d like to think that if I could&rsquo;ve gotten this patch to work, the entire workload could be offloaded to the GPU and I could&rsquo;ve easily achieved 1080p 60 FPS. So, in its current state, the best I could do was to use the non-nvidia <strong>jpegdec</strong> element and offload the jpeg decoding to the CPU. Maybe when I come back to this project I&rsquo;ll have some more time to look into this further or get some more help.</p><p>In the meantime, however, I accepted the performance hit and created a <strong>systemd service</strong> to launch the pipeline and get things started automatically.</p><h3 id=network-stream>Network Stream<a hidden class=anchor aria-hidden=true href=#network-stream>#</a></h3><p>Once the Jetson did its part to decode the MJPEG and encode it in H.264, all it had to do was send it over the network to an RTMP server. This way, I could access the video stream as an RTMP video input on another server running OBS. Additionally, I could also use that RTMP server to rebroadcast the stream from OBS to multiple streaming platforms.</p><p>Initially, I didn&rsquo;t have a server with a GPU to run OBS and efficiently encode its own stream, so I used my desktop. While this worked fine, I didn&rsquo;t want to have to leave on an R9-390X heater in my room, and I didn&rsquo;t have much faith in that being a stable set up anyways.</p><p>So, rather than pulling in the stream from the Jetson on some OBS instance, I instead decided that I would just send the stream from the Jetson to the RTMP server, and then directly from the RTMP endpoint to all of the broadcasting platforms I wanted.</p><h3 id=the-result-for-now>The Result (For Now)<a hidden class=anchor aria-hidden=true href=#the-result-for-now>#</a></h3><p>So far, the basic stream set up works almost all on its own, but often needs some attention. Whether its setting the camera back up after a brown-out or restarting the stream due to me bringing the network down.</p><p>Depending on whether or not I&rsquo;m working on it or messing with something, you will usually find the stream up at the <a href=https://www.youtube.com/channel/UCZFFMh3HpP20QYtKPAVvCPg>feeder&rsquo;s dedicated YouTube Channel Chirp</a>.
<img loading=lazy src=/posts/birdstream/chirp.jpg alt=Chirp></p><p>Until I add some better automation, when the stream is up, it runs 24/7, so you can check it out anytime (though you won&rsquo;t see too much at night!).</p><h3 id=whats-still-to-come>What&rsquo;s Still To Come<a hidden class=anchor aria-hidden=true href=#whats-still-to-come>#</a></h3><p>Busy with school and internship work, I haven&rsquo;t quite had the time yet to build out the automation scripts to control OBS. Plus, I have temporarily replaced the Jetson with another old Windows desktop until I have more time to work with it.</p><h4 id=stream-control-scripts>Stream Control Scripts<a hidden class=anchor aria-hidden=true href=#stream-control-scripts>#</a></h4><p>Just to clarify, these should just be some basic Python scripts or maybe an API of some sort that I can use to control the stream. That is, they will automate starting/stopping the stream based on the time of day, switching scenes to a different camera, etc.</p><h4 id=multiple-cameras>Multiple Cameras<a hidden class=anchor aria-hidden=true href=#multiple-cameras>#</a></h4><p>Speaking of more cameras: Yes! I bought yet another Vixia. This time around, I found a great deal on an <strong>HF R400</strong>. I did some more research on these cameras and eventually realized that there haven&rsquo;t been any significant changes the underlying camera platform since the 400 up to the 800 (like my R82). That in mind, I found a good deal on one and jumped on it.</p><p>Now, I didn&rsquo;t just buy another camera to have a picture in picture or something like that&ndash;no. I wanted to solve the problem of not being able to get up close and personal with the birds on a particular feeder. The stream is SO much cooler to watch when the entire shot is a close up of some bird. Otherwise, we&rsquo;re stuck with the pretty bog-standard <em>webcam-like</em> view of the birds that just isn&rsquo;t as captivating.</p><h4 id=object-detection-machine-learning-birds>Object Detection? Machine Learning? Birds?<a hidden class=anchor aria-hidden=true href=#object-detection-machine-learning-birds>#</a></h4><p>Buzzwords aside, what&rsquo;s the plan for these cameras then? Well, the idea is to direct each camera at only a single feeder or group of feeders. THEN, using some sort of object detection machine learning model (maybe some smaller YOLO model or similar), I can switch to whichever camera sees the most birds, for instance&ndash;something along those lines. This way, the feeder stream offers a totally hands-off, automated, and intelligent view of our local birds.</p><p>Plus, if I go deeper down the machine learning rabbit-hole (or if someone else does and I just use their model), I may even be able to classify different birds as they appear! For now, these are future plans that don&rsquo;t have time allotted to them yet, but in time I hope to bring them to life.</p><h4 id=where-will-these-machine-learning-models-run>Where Will These Machine Learning Models Run?<a hidden class=anchor aria-hidden=true href=#where-will-these-machine-learning-models-run>#</a></h4><p>I have no idea. I still a lot of playing around with stuff like this to figure out what exactly I&rsquo;ll need to pull it off. It&rsquo;d be great if the Jetson could run models like this&ndash;In fact, I don&rsquo;t think it&rsquo;s unheard of to run Yolo (at some framerate) on the Jetson Nano. However, more sophisticated or less efficient models may to prove to be a bit less forgiving.</p><p>In any case, running the models <em>&ldquo;at the edge&rdquo;</em> would be great! I would imagine the Jetson&rsquo;s SOC would run things like this much more efficiently in terms of power, despite maybe not being as performant. If not, however, running one of these models on one of my servers with an a GTX 1050 also wouldn&rsquo;t be out of the question.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://nlitz88.github.io/posts/dft/dft/><span class=title>« Prev</span><br><span>The Discrete Fourier Transform - Conceptual Overview and Practical Notes</span></a>
<a class=next href=https://nlitz88.github.io/posts/filesystem/filesystem/><span class=title>Next »</span><br><span>FS3 - My Mock File System</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://nlitz88.github.io/>Nathan Litzinger</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById("menu");menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>